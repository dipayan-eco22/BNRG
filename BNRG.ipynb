{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BNRG.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZdsmTdwK6Y9r"
      },
      "outputs": [],
      "source": [
        "#package import statements\n",
        "import random\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Function for belief agggregation and updation\n",
        "def next_period_beliefs(number_of_agents,beliefs,relationship_matrix,weight_matrix):\n",
        "    weight_matrix_star=np.sum(np.multiply(weight_matrix,relationship_matrix),axis = 1)# axis = 1 means horizontal summation\n",
        "    weight_matrix_star_resizer=np.reshape(np.repeat(weight_matrix_star,number_of_agents,axis=0),(number_of_agents,number_of_agents))\n",
        "    weight_matrix_star_restricted=np.divide(np.multiply(weight_matrix,relationship_matrix),weight_matrix_star_resizer)\n",
        "    return np.matmul(weight_matrix_star_restricted,beliefs)"
      ],
      "metadata": {
        "id": "UZEoX1yW6yrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to find the immediate neighbours of an agent\n",
        "def neighbours(agent):\n",
        "    nei=[]\n",
        "    for i in range(len(agent)):\n",
        "        if agent[i] == 1:\n",
        "            nei.append(i)\n",
        "    return nei   "
      ],
      "metadata": {
        "id": "a4H3WOO960PT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function defining the neighbourhood change process\n",
        "def neighbour_change(number_of_agents,relationship_matrix,beliefs,ub=0.1,lb=0.1):\n",
        "    for agent in range(number_of_agents):\n",
        "        # key agent has connections or is neighbours with nei\n",
        "        nei = neighbours(relationship_matrix[agent])\n",
        "        diff=[]\n",
        "        for i in nei:\n",
        "            diff.append(abs(beliefs[agent]- beliefs[i]))\n",
        "        nei_be = beliefs[[i for i,x in enumerate(diff) if x == max(diff)][0]]\n",
        "        if nei_be <= min(1,beliefs[agent]+ub) and nei_be >= max(0,beliefs[agent]-lb):\n",
        "            replaced_neighbour = neighbours(relationship_matrix[agent])[[i for i,x in enumerate(diff) if x == max(diff)][0]]\n",
        "            nei.remove(replaced_neighbour)# this removes the neighbour with the max difference in belief given that it is outside the bounds\n",
        "            nei_nei = []\n",
        "            for i in nei:\n",
        "                neigh = neighbours(relationship_matrix[i])\n",
        "                for j in neigh:\n",
        "                    nei_nei.append(j)\n",
        "            nei_nei= list(set(nei_nei))\n",
        "            for i in nei:\n",
        "                if i in nei_nei:\n",
        "                    nei_nei.remove(i)\n",
        "            simi = []\n",
        "            for i in nei_nei:\n",
        "                simi.append(abs(beliefs[agent]- beliefs[i]))\n",
        "            if len(simi)>0:\n",
        "                added_neighbour = nei_nei[[i for i,x in enumerate(simi) if x == min(simi)][0]]\n",
        "                relationship_matrix[agent][replaced_neighbour] = 0\n",
        "                relationship_matrix[replaced_neighbour][agent] = 0\n",
        "                relationship_matrix[agent][added_neighbour] = 1\n",
        "                relationship_matrix[added_neighbour][agent] = 1\n",
        "    return relationship_matrix"
      ],
      "metadata": {
        "id": "0xDkg5fk60Mz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_graphs(time_periods,consensus,number_of_agents):\n",
        "    for i in range(len(consensus)):\n",
        "        plt.plot(np.linspace(0,time_periods,time_periods+1),list(consensus.iloc[i]),lw= 1)\n",
        "        plt.xlabel(\"Time\")\n",
        "        plt.ylabel(\"Belief values\")\n",
        "        plt.title(str(number_of_agents)+\" Agents\")"
      ],
      "metadata": {
        "id": "XLagenaU7E9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Complete Graph Model"
      ],
      "metadata": {
        "id": "rY4lpZIP7QQW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def siml(number_of_agents,time_periods):\n",
        "    #Network = nx.Graph()\n",
        "    # randomly generating initial belief values i.e. x(t) for the agents and storing them in the node \n",
        "    '''\n",
        "    beliefs = []\n",
        "    for i in range(number_of_agents):\n",
        "        belf = np.random.rand(1)[0]\n",
        "        #Network.add_node(i,belief = belf)\n",
        "        beliefs.append(belf)\n",
        "    '''\n",
        "    beliefs=np.random.uniform(0,1,number_of_agents)\n",
        "    relationship_matrix= np.where(np.random.rand(number_of_agents,number_of_agents) + np.identity(number_of_agents) > 0.0, 1, 0)\n",
        "    weight_matrix = np.random.rand(number_of_agents,number_of_agents)\n",
        "    \n",
        "    consensus = pd.DataFrame({'t0':beliefs})\n",
        "    b=beliefs\n",
        "    for i in range(time_periods):\n",
        "        b=next_period_beliefs(number_of_agents,b, relationship_matrix, weight_matrix)\n",
        "        consensus.insert(loc= len(consensus.columns),column = ('t'+str(i+1)),value= b)\n",
        "    return consensus"
      ],
      "metadata": {
        "id": "Hr9G6GWz6_Rx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def auto_siml(number_of_agents):\n",
        "    #Network = nx.Graph()\n",
        "    # randomly generating initial belief values i.e. x(t) for the agents and storing them in the node \n",
        "    '''\n",
        "    beliefs = []\n",
        "    for i in range(number_of_agents):\n",
        "        belf = np.random.rand(1)[0]\n",
        "        #Network.add_node(i,belief = belf)\n",
        "        beliefs.append(belf)\n",
        "    '''\n",
        "    beliefs=np.random.uniform(0,1,number_of_agents)\n",
        "    relationship_matrix= np.ones((number_of_agents,number_of_agents))\n",
        "    weight_matrix = np.random.rand(number_of_agents,number_of_agents)\n",
        "    \n",
        "    consensus = pd.DataFrame({'t0':beliefs})\n",
        "    b=beliefs\n",
        "    t=0\n",
        "    consensus_final = list(consensus[consensus.columns[-1]])\n",
        "    dif_sum=[]\n",
        "    for j in consensus_final:\n",
        "        for k in consensus_final:\n",
        "            dif_sum.append(abs(j-k))\n",
        "    while(sum(dif_sum)/len(dif_sum) > 0.001):\n",
        "        t=t+1\n",
        "        if t > 99:\n",
        "            break\n",
        "        b=next_period_beliefs(number_of_agents,b, relationship_matrix, weight_matrix)\n",
        "        consensus.insert(loc= len(consensus.columns),column = ('t'+str(t)),value= b)\n",
        "        consensus_final = list(consensus[consensus.columns[-1]])\n",
        "        dif_sum=[]\n",
        "        for j in consensus_final:\n",
        "            for k in consensus_final:\n",
        "                dif_sum.append(abs(j-k))\n",
        "    return t"
      ],
      "metadata": {
        "id": "UmFFC0iM60KT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "complete_graph_sim =pd.DataFrame()\n",
        "for s in tqdm(range(101)):\n",
        "    time_required=[]\n",
        "    for i in range(2,102):\n",
        "        time_required.append(auto_siml(i))\n",
        "    complete_graph_sim.insert(loc= len(complete_graph_sim.columns),column = \"sim_\"+str(s),value = time_required)"
      ],
      "metadata": {
        "id": "0yXJNqFp-2Jt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean=complete_graph_sim.mean(axis=1)\n",
        "complete_graph_sim.insert(loc=len(complete_graph_sim.columns),column = \"number_of_agents\",value = np.linspace(2,101,100) )\n",
        "complete_graph_sim.insert(loc=len(complete_graph_sim.columns),column = \"Mean\",value =mean )\n",
        "complete_graph_sim.to_csv('complete_graph_sim.csv') # to save the results to a csv file."
      ],
      "metadata": {
        "id": "DFPaUncz-7kE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Restricted Graph Model"
      ],
      "metadata": {
        "id": "hA8VBu1l7hzM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def siml(number_of_agents,time_periods):\n",
        "    #Network = nx.Graph()\n",
        "    # randomly generating initial belief values i.e. x(t) for the agents and storing them in the node \n",
        "    sparseness=0.5\n",
        "    beliefs=np.random.uniform(0,1,number_of_agents)\n",
        "    a = np.random.rand(number_of_agents,number_of_agents)\n",
        "    relationship_matrix = np.where((np.tril(a) + np.tril(a, -1).T)+np.eye(number_of_agents)>sparseness,1,0)\n",
        "    weight_matrix = np.random.rand(number_of_agents,number_of_agents)\n",
        "    \n",
        "    consensus = pd.DataFrame({'t0':beliefs})\n",
        "    b=beliefs\n",
        "    for i in range(time_periods):\n",
        "        b=next_period_beliefs(number_of_agents,b, relationship_matrix, weight_matrix)\n",
        "        consensus.insert(loc= len(consensus.columns),column = ('t'+str(i+1)),value= b)\n",
        "    return consensus"
      ],
      "metadata": {
        "id": "OjlPBf4K60Hr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def auto_siml(number_of_agents):\n",
        "    #Network = nx.Graph()\n",
        "    # randomly generating initial belief values i.e. x(t) for the agents and storing them in the node \n",
        "    #print('3')\n",
        "    sparseness=0.75\n",
        "    beliefs=np.random.uniform(0,1,number_of_agents)\n",
        "    a = np.random.rand(number_of_agents,number_of_agents)\n",
        "    relationship_matrix = np.where((np.tril(a) + np.tril(a, -1).T)+np.eye(number_of_agents)>sparseness,1,0)\n",
        "    weight_matrix = np.random.rand(number_of_agents,number_of_agents)\n",
        "\n",
        "    consensus = pd.DataFrame({'t0':beliefs})\n",
        "    b=beliefs.copy()\n",
        "    t=0\n",
        "    consensus_final = list(consensus[consensus.columns[-1]])\n",
        "    dif_sum=[]\n",
        "    for j in consensus_final:\n",
        "        for k in consensus_final:\n",
        "            dif_sum.append(abs(j-k))\n",
        "    while(sum(dif_sum)/len(dif_sum) > 0.001):\n",
        "        t=t+1\n",
        "        if t>99:\n",
        "            break\n",
        "        b=next_period_beliefs(number_of_agents,b, relationship_matrix, weight_matrix)\n",
        "        consensus.insert(loc= len(consensus.columns),column = ('t'+str(t)),value= b)\n",
        "        consensus_final = list(consensus[consensus.columns[-1]])\n",
        "        dif_sum=[]\n",
        "        for j in consensus_final:\n",
        "            for k in consensus_final:\n",
        "                dif_sum.append(abs(j-k))\n",
        "    return t"
      ],
      "metadata": {
        "id": "dp5mqu8060FC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "restricted_graph_sim =pd.DataFrame()\n",
        "for s in tqdm(range(101)):\n",
        "    #print('1')\n",
        "    time_required=[]\n",
        "    for i in range(2,101):\n",
        "        #print('2')\n",
        "        time_required.append(auto_siml(i))\n",
        "    restricted_graph_sim.insert(loc= len(restricted_graph_sim.columns),column = \"sim_\"+str(s),value = time_required)"
      ],
      "metadata": {
        "id": "pyIPq4xM_PcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean=restricted_graph_sim.mean(axis=1)\n",
        "restricted_graph_sim.insert(loc=len(restricted_graph_sim.columns),column = \"number_of_agents\",value = np.linspace(2,101,100) )\n",
        "restricted_graph_sim.insert(loc=len(restricted_graph_sim.columns),column = \"Mean\",value =mean )\n",
        "restricted_graph_sim.to_csv('restricted_graph_302_s=0.75.csv')"
      ],
      "metadata": {
        "id": "6tZAeOCT_TTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Restricted Graph Model with Neighbour Change"
      ],
      "metadata": {
        "id": "SBWxU0Cf70Io"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def siml(number_of_agents,time_periods):\n",
        "    #Network = nx.Graph()\n",
        "    # randomly generating initial belief values i.e. x(t) for the agents and storing them in the node \n",
        "    sparseness=0.5\n",
        "    beliefs=np.random.uniform(0,1,number_of_agents)\n",
        "    a = np.random.rand(number_of_agents,number_of_agents)\n",
        "    relationship_matrix = np.where((np.tril(a) + np.tril(a, -1).T)+np.eye(number_of_agents)>sparseness,1,0)\n",
        "    weight_matrix = np.random.rand(number_of_agents,number_of_agents)\n",
        "    a=relationship_matrix.copy()\n",
        "    consensus = pd.DataFrame({'t0':beliefs})\n",
        "    b=beliefs\n",
        "    for i in range(time_periods):\n",
        "        relationship_matrix=neighbour_change(number_of_agents,relationship_matrix,b,0.1,0.1)\n",
        "        b=next_period_beliefs(number_of_agents,b, relationship_matrix, weight_matrix)\n",
        "        consensus.insert(loc= len(consensus.columns),column = ('t'+str(i+1)),value= b)\n",
        "    print((number_of_agents*number_of_agents)-(a==relationship_matrix).sum())\n",
        "    return consensus"
      ],
      "metadata": {
        "id": "2POlQDxS60Cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def auto_siml(number_of_agents):\n",
        "    #Network = nx.Graph()\n",
        "    # randomly generating initial belief values i.e. x(t) for the agents and storing them in the node \n",
        "    sparseness=0.75\n",
        "    beliefs=np.random.uniform(0,1,number_of_agents)\n",
        "    a = np.random.rand(number_of_agents,number_of_agents)\n",
        "    relationship_matrix = np.where((np.tril(a) + np.tril(a, -1).T)+np.eye(number_of_agents)>sparseness,1,0)\n",
        "    weight_matrix = np.random.rand(number_of_agents,number_of_agents)\n",
        "    a=relationship_matrix.copy()\n",
        "    consensus = pd.DataFrame({'t0':beliefs})\n",
        "    b=beliefs\n",
        "    t=0\n",
        "    consensus_final = list(consensus[consensus.columns[-1]])\n",
        "    dif_sum=[]\n",
        "    for j in consensus_final:\n",
        "        for k in consensus_final:\n",
        "            dif_sum.append(abs(j-k))\n",
        "    while(sum(dif_sum)/len(dif_sum) > 0.001):\n",
        "        t=t+1\n",
        "        if t > 99:\n",
        "            break\n",
        "        relationship_matrix=neighbour_change(number_of_agents,relationship_matrix,b,0.1,0.1)\n",
        "        b=next_period_beliefs(number_of_agents,b, relationship_matrix, weight_matrix)\n",
        "        consensus.insert(loc= len(consensus.columns),column = ('t'+str(t)),value= b)\n",
        "        consensus_final = list(consensus[consensus.columns[-1]])\n",
        "        dif_sum=[]\n",
        "        for j in consensus_final:\n",
        "            for k in consensus_final:\n",
        "                dif_sum.append(abs(j-k))\n",
        "    return t"
      ],
      "metadata": {
        "id": "4GJdhTQ28MCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "restricted_graph_w_nei_sim = pd.DataFrame()\n",
        "for s in tqdm(range(101)):\n",
        "    #print(s)\n",
        "    time_required=[]\n",
        "    for i in range(2,102):\n",
        "        #print(i)\n",
        "        time_required.append(auto_siml(i))     \n",
        "    restricted_graph_w_nei_sim.insert(loc= len(restricted_graph_w_nei_sim.columns),column = \"sim_\"+str(s),value = time_required)"
      ],
      "metadata": {
        "id": "g5wpdEPP_tOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean=restricted_graph_w_nei_sim.mean(axis=1)\n",
        "restricted_graph_w_nei_sim.insert(loc=len(restricted_graph_w_nei_sim.columns),column = \"number_of_agents\",value = np.linspace(2,101,100) )\n",
        "restricted_graph_w_nei_sim.insert(loc=len(restricted_graph_w_nei_sim.columns),column = \"Mean\",value =mean )\n",
        "restricted_graph_w_nei_sim.to_csv('restricted_graph_w_nei_S=0.75.csv')"
      ],
      "metadata": {
        "id": "J48DwRQK_s9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Restricted Graph Model with Unlimited Neighbour Change "
      ],
      "metadata": {
        "id": "sr7Sz-r98wuZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def siml(number_of_agents,time_periods):\n",
        "    #Network = nx.Graph()\n",
        "    # randomly generating initial belief values i.e. x(t) for the agents and storing them in the node \n",
        "    sparseness=0.5\n",
        "    beliefs=np.random.uniform(0,1,number_of_agents)\n",
        "    a = np.random.rand(number_of_agents,number_of_agents)\n",
        "    relationship_matrix = np.where((np.tril(a) + np.tril(a, -1).T)+np.eye(number_of_agents)>sparseness,1,0)\n",
        "    weight_matrix = np.random.rand(number_of_agents,number_of_agents)\n",
        "    a=relationship_matrix.copy()\n",
        "    consensus = pd.DataFrame({'t0':beliefs})\n",
        "    b=beliefs\n",
        "    for i in range(time_periods):\n",
        "        saved_relationmatrix = relationship_matrix.copy()\n",
        "        last_change=0\n",
        "        relationship_matrix=neighbour_change(number_of_agents,relationship_matrix,b,0.1,0.1)\n",
        "        change = (relationship_matrix==relationship_matrix.T).sum() - (saved_relationmatrix==relationship_matrix).sum()\n",
        "        while (change-last_change >0):\n",
        "            last_change = change\n",
        "            relationship_matrix=neighbour_change(number_of_agents,relationship_matrix,b,0.1,0.1)\n",
        "            change = (relationship_matrix==relationship_matrix.T).sum() - (saved_relationmatrix==relationship_matrix).sum()\n",
        "        b=next_period_beliefs(number_of_agents,b, relationship_matrix, weight_matrix)\n",
        "        consensus.insert(loc= len(consensus.columns),column = ('t'+str(i+1)),value= b)\n",
        "    print((number_of_agents*number_of_agents)-(a==relationship_matrix).sum())\n",
        "    return consensus"
      ],
      "metadata": {
        "id": "OmlY-Y806z_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def auto_siml(number_of_agents):\n",
        "    #Network = nx.Graph()\n",
        "    # randomly generating initial belief values i.e. x(t) for the agents and storing them in the node \n",
        "    sparseness=0.75\n",
        "    beliefs=np.random.uniform(0,1,number_of_agents)\n",
        "    a = np.random.rand(number_of_agents,number_of_agents)\n",
        "    relationship_matrix = np.where((np.tril(a) + np.tril(a, -1).T)+np.eye(number_of_agents)>sparseness,1,0)\n",
        "    weight_matrix = np.random.rand(number_of_agents,number_of_agents)\n",
        "    a=relationship_matrix.copy()\n",
        "    consensus = pd.DataFrame({'t0':beliefs})\n",
        "    b=beliefs\n",
        "    t=0\n",
        "    consensus_final = list(consensus[consensus.columns[-1]])\n",
        "    dif_sum=[]\n",
        "    for j in consensus_final:\n",
        "        for k in consensus_final:\n",
        "            dif_sum.append(abs(j-k))\n",
        "    while(sum(dif_sum)/len(dif_sum) > 0.001):\n",
        "        t=t+1\n",
        "        if t > 199:\n",
        "            break\n",
        "        saved_relationmatrix = relationship_matrix.copy()\n",
        "        last_change=0\n",
        "        relationship_matrix=neighbour_change(number_of_agents,relationship_matrix,b,0.1,0.1)\n",
        "        change = (relationship_matrix==relationship_matrix.T).sum() - (saved_relationmatrix==relationship_matrix).sum()\n",
        "        while (change-last_change >0):\n",
        "            last_change = change\n",
        "            relationship_matrix=neighbour_change(number_of_agents,relationship_matrix,b,0.1,0.1)\n",
        "            change = (relationship_matrix==relationship_matrix.T).sum() - (saved_relationmatrix==relationship_matrix).sum()\n",
        "        b=next_period_beliefs(number_of_agents,b, relationship_matrix, weight_matrix)\n",
        "        consensus.insert(loc= len(consensus.columns),column = ('t'+str(t)),value= b)\n",
        "        consensus_final = list(consensus[consensus.columns[-1]])\n",
        "        dif_sum=[]\n",
        "        for j in consensus_final:\n",
        "            for k in consensus_final:\n",
        "                dif_sum.append(abs(j-k))\n",
        "    return t"
      ],
      "metadata": {
        "id": "Mm-3nY1r8MHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "restricted_graph_w_uc_nei_sim = pd.DataFrame()\n",
        "for s in tqdm(range(101)):\n",
        "    #print(s)\n",
        "    time_required=[]\n",
        "    for i in range(2,102):\n",
        "        print(i)\n",
        "        time_required.append(auto_siml(i))     \n",
        "    restricted_graph_w_uc_nei_sim.insert(loc= len(restricted_graph_w_uc_nei_sim.columns),column = \"sim_\"+str(s),value = time_required)"
      ],
      "metadata": {
        "id": "AbHm661G8MXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean=restricted_graph_w_uc_nei_sim.mean(axis=1)\n",
        "restricted_graph_w_uc_nei_sim.insert(loc=len(restricted_graph_w_uc_nei_sim.columns),column = \"number_of_agents\",value = np.linspace(2,101,100) )\n",
        "restricted_graph_w_uc_nei_sim.insert(loc=len(restricted_graph_w_uc_nei_sim.columns),column = \"Mean\",value =mean )\n",
        "restricted_graph_w_uc_nei_sim.to_csv('restricted_graph_w_uc_nei_sim_S=0.75_test.csv')"
      ],
      "metadata": {
        "id": "ie8bPuB38Mmu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}